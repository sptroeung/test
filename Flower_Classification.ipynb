{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Flower Classification Competition (15%)**\n",
        "For this competition, we will use the Flower Recognition (https://cloudstor.aarnet.edu.au/plus/s/1n6XuPUCwJ0MkgN). This dataset contains 4317 images of flowers. The data collection is based on the data from flickr, google images, yandex images. The aim is to recognize flower species from a photo.  \n",
        "\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion. For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Note that for this dataset the photos are not all at a fixed size, they have different proportions.\n",
        "\n",
        "We provide baseline code that includes the following features:\n",
        "\n",
        "*   Loading and Analysing the Flowers dataset using torchvision.\n",
        "*   Providing some augmentations (on loading) \n",
        "*   Defining a simple convolutional neural network. \n",
        "*   How to use existing loss function for the model learning. \n",
        "*   Train the network on the training data. \n",
        "*   Test the trained network on the testing data. \n",
        "*   Generate prediction for the random test image(s). \n",
        "\n",
        "The following improvements could be considered:\n",
        "-------\n",
        "1. Change of advanced training parameters: Learning Rate, Optimizer, Batch-size, Number of Max Epochs, and Drop-out. \n",
        "2. Use of a new loss function.\n",
        "3. Additional/better data augmentation\n",
        "4. Architectural Changes: Batch Normalization, Residual layers, Attention Block, and other variants.\n",
        "\n",
        "Your code should be modified from the provided baseline. A pdf report of a maximum of two pages is required to explain the changes you made from the baseline, why you chose those changes, and the improvements they achieved.\n",
        "\n",
        "Marking Rules:\n",
        "-------\n",
        "We will mark the competition based on the final test accuracy on testing images and your report.\n",
        "\n",
        "Final mark (out of 50) = acc_mark + efficiency mark + report mark\n",
        "###Acc_mark 10:\n",
        "\n",
        "We will rank all the submission results based on their test accuracy. Zero improvement over the baseline yields 0 marks. Maximum improvement over the baseline will yield 10 marks. There will be a sliding scale applied in between.\n",
        "\n",
        "###Efficiency mark 10:\n",
        "\n",
        "Efficiency considers not only the accuracy, but the computational cost of running the model (flops: https://en.wikipedia.org/wiki/FLOPS). Efficiency for our purposes is defined to be the ratio of accuracy (in %) to Gflops. Please report the computational cost for your final model and include the efficiency calculation in your report. Maximum improvement over the baseline will yield 10 marks. Zero improvement over the baseline yields zero marks, with a sliding scale in between.\n",
        "\n",
        "###Report mark 30:\n",
        "Your report should comprise:\n",
        "1. An introduction showing your understanding of the task and of the baseline model: [10 marks]\n",
        "\n",
        "2. A description of how you have modified aspects of the system to improve performance. [10 marks]\n",
        "\n",
        "A recommended way to present a summary of this is via an \"ablation study\" table, eg:\n",
        "\n",
        "|Method1|Method2|Method3|Accuracy|\n",
        "|---|---|---|---|\n",
        "|N|N|N|60%|\n",
        "|Y|N|N|65%|\n",
        "|Y|Y|N|77%|\n",
        "|Y|Y|Y|82%|\n",
        "\n",
        "3. Explanation of the methods for reducing the computational cost and/or improve the trade-off between accuracy and cost: [5 marks]\n",
        "\n",
        "4. Limitations/Conclusions: [5 marks] "
      ],
      "metadata": {
        "id": "uFi4isLLqWzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################################################################################\n",
        "### Subject: Computer Vision \n",
        "### Year: 2023\n",
        "### Student Name: ABC, XYZ\n",
        "### Student ID: a123456, a654321\n",
        "### Comptetion Name: Flowers Classification Competition\n",
        "### Final Results:\n",
        "### ACC:         FLOPs:\n",
        "##################################################################################################################################"
      ],
      "metadata": {
        "id": "21p5S0cCYPwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries. \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "# To avoid non-essential warnings \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models \n",
        "from torchvision.utils import make_grid\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "I0d4smZzvzWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Image Transformations. \n",
        "\n",
        "train_transform=transforms.Compose([\n",
        "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
        "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "YCB13oubv4es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting G-Drive to get your dataset. \n",
        "# To access Google Colab GPU; Go To: Edit >>> Network Settings >>> Hardware Accelarator: Select GPU. \n",
        "# Reference: https://towardsdatascience.com/google-colab-import-and-export-datasets-eccf801e2971 \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset path.\n",
        "data_directory = '/content/drive/MyDrive/Datasets/flower/flowers'\n",
        "dataset=datasets.ImageFolder(root=data_directory,transform=train_transform)\n",
        "dataset"
      ],
      "metadata": {
        "id": "UE2dpR5MJJSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the flower class types.\n",
        "class_names=dataset.classes\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ],
      "metadata": {
        "id": "4Qm4fSHNv8uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Test data split. \n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset.targets))), test_size=0.2, stratify=dataset.targets)\n",
        "train_data = torch.utils.data.Subset(dataset, train_indices)\n",
        "test_data = torch.utils.data.Subset(dataset, test_indices)"
      ],
      "metadata": {
        "id": "7F89K2Gnv-3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_data,batch_size=10,shuffle=True)\n",
        "test_loader=DataLoader(test_data,batch_size=10)"
      ],
      "metadata": {
        "id": "TTc8_5kuwAdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "KhcdYzW7wCEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview of the datasets. \n",
        "for images, labels in train_loader:\n",
        "    break\n",
        "#print the labels\n",
        "print('Label:', labels.numpy())\n",
        "print('Class:', *np.array([class_names[i] for i in labels]))\n",
        "\n",
        "im=make_grid(images,nrow=5)"
      ],
      "metadata": {
        "id": "3DYug9QmwDb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
      ],
      "metadata": {
        "id": "9PJM4MUowFAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse Normalization. \n",
        "inv_normalize=transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],\n",
        "                                     std=[1/0.229,1/0.224,1/0.225])\n",
        "im=inv_normalize(im)"
      ],
      "metadata": {
        "id": "-DpSEbX4wGjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
      ],
      "metadata": {
        "id": "vI94skaTwIeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional Network - Baseline\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self, classes):\n",
        "        super().__init__()\n",
        "        self.num_classes=classes\n",
        "        self.conv1=nn.Conv2d(3,6,3,1)\n",
        "        self.conv2=nn.Conv2d(6,16,3,1)\n",
        "        self.fc1=nn.Linear(16*54*54,120) \n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3=nn.Linear(84,20)\n",
        "        self.fc4=nn.Linear(20,self.num_classes)\n",
        "    def forward(self,X):\n",
        "        X=F.relu(self.conv1(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=F.relu(self.conv2(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=X.view(-1,16*54*54)\n",
        "        X=F.relu(self.fc1(X))\n",
        "        X=F.relu(self.fc2(X))\n",
        "        X=F.relu(self.fc3(X))\n",
        "        X=self.fc4(X)\n",
        "        \n",
        "        return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "cVa0CwMlwKRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "CNNmodel=ConvolutionalNetwork(num_classes)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(CNNmodel.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "thnr0iFSwNzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNNmodel"
      ],
      "metadata": {
        "id": "Yoqv5LPnwQsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting of number of parameters in the model.\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>8}')\n",
        "    print(f'________\\n{sum(params):>8}')\n",
        "count_parameters(CNNmodel)"
      ],
      "metadata": {
        "id": "j-jnIKVGwRjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Schema.\n",
        "import time\n",
        "start_time=time.time()\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "train_correct=[]\n",
        "test_correct=[]\n",
        "epochs=5\n",
        "\n",
        "for i in range(epochs):\n",
        "    trn_corr=0\n",
        "    tst_corr=0\n",
        "    for b, (X_train,y_train) in enumerate(train_loader):\n",
        "        b+=1                                            \n",
        "        y_pred=CNNmodel(X_train)\n",
        "        loss=criterion(y_pred,y_train)\n",
        "\n",
        "        predicted=torch.max(y_pred.data,1)[1]\n",
        "        batch_corr=(predicted==y_train).sum()\n",
        "        trn_corr+=batch_corr\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if b%200==0:\n",
        "            print(f\"epoch: {i} loss: {loss.item} batch: {b} accuracy: {trn_corr.item()*100/(10*b):7.3f}%\")\n",
        "    loss=loss.detach().numpy()\n",
        "    train_losses.append(loss)\n",
        "    train_correct.append(trn_corr)\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for b, (X_test,y_test) in enumerate(test_loader):\n",
        "            y_val=CNNmodel(X_test)\n",
        "            loss=criterion(y_val,y_test)\n",
        "            \n",
        "            predicted=torch.max(y_val.data,1)[1]\n",
        "            btach_corr=(predicted==y_test).sum()\n",
        "            tst_corr+=btach_corr\n",
        "            \n",
        "        loss=loss.detach().numpy()\n",
        "        test_losses.append(loss)\n",
        "        test_correct.append(tst_corr)\n",
        "        \n",
        "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')"
      ],
      "metadata": {
        "id": "umcXykKiwTO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting loss over time. \n",
        "plt.plot(train_losses,label=\"train_losses\")\n",
        "plt.plot(test_losses,label=\"test_losses\")\n",
        "plt.legend()\n",
        "train_losses"
      ],
      "metadata": {
        "id": "VNkT5PRDwZPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=100\n",
        "im = inv_normalize(test_data[x][0])\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
      ],
      "metadata": {
        "id": "_GjQkrBmwfIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[x][0].shape"
      ],
      "metadata": {
        "id": "qIqcrg3ewg6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction for one of the samples. \n",
        "CNNmodel.eval()\n",
        "with torch.no_grad():\n",
        "    new_pred=CNNmodel(test_data[x][0].view(1,3,224,224)).argmax()\n",
        "print(f'Predicted value: {new_pred.item()} {class_names[new_pred.item()]}')"
      ],
      "metadata": {
        "id": "2sMnmF4pwi0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FLOPs"
      ],
      "metadata": {
        "id": "AFq_CVljVDrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #The code from https://cloudstor.aarnet.edu.au/plus/s/PcSc67ZncTSQP0E can be used to count flops\n",
        "  #Download the code.\n",
        "  !wget -c https://cloudstor.aarnet.edu.au/plus/s/hXo1dK9SZqiEVn9/download\n",
        "  !mv download FLOPs_counter.py\n",
        "  #!rm -rf download"
      ],
      "metadata": {
        "id": "ghA9KF-1UgBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from FLOPs_counter import print_model_parm_flops\n",
        "input = torch.randn(1, 3, 224, 224) # The input size should be the same as the size that you put into your model \n",
        "#Get the network and its FLOPs\n",
        "num_classes = 5\n",
        "model = ConvolutionalNetwork(num_classes)\n",
        "print_model_parm_flops(model, input, detail=False)"
      ],
      "metadata": {
        "id": "Cq22AiKTVHMx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}