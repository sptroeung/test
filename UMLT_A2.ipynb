{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Classification\n",
    "# Using Machine Learning Tools CS3317\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will apply some popular machine learning techniques to the problem of classifying data from histological cell images for the diagnosis of malignant breast cancer. This will be presented as a practical scenario where you are approached by a client to solve a problem.  \n",
    "\n",
    "The main aims of this assignment are: \n",
    "\n",
    "- to use the best practice machine learning workflow for producing a solution to a client's problem;\n",
    "- to visualise data and determine the best pre-processing;\n",
    "- to create the necessary datasets for training and testing purposes;\n",
    "- to train and optimise a selection of models, then choose the best;\n",
    "- to obtain an unbiased measurement of the final model's performance;\n",
    "- to interpret results clearly and concisely.\n",
    "\n",
    "This assignment relates to the following ACS CBOK areas: abstraction, design, hardware and software, data and information, HCI and programming.\n",
    "\n",
    "## General instructions\n",
    "\n",
    "This assignment is divided into several tasks. Use the spaces provided in this notebook to answer the questions posed in each task. Note that some questions require writing a small amount of code, some require graphical results. \n",
    "\n",
    "**Do not** manually edit the data set file we have provided! For marking purposes, it's important that your code runs correctly on the original data file.\n",
    "\n",
    "Some of the parts of this assignment build on the workflow from the first assignment and that part of the course, and so less detailed instructions are provided for this, as you should be able to implement this workflow now without low-level guidance. A substantial portion of the marks for this assignment are associated with making the right choices and executing this workflow correctly and efficiently.\n",
    "\n",
    "This assignment can be solved using methods from [sklearn](https://scikit-learn.org/stable/index.html), [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html), and [matplotlib](https://matplotlib.org/stable/index.html) as presented in the workshops. **Other libraries should not be used** (even though they might have nice functionality) and certain restrictions on sklearn functions will be made clear in the instruction text. You are expected to search and carefully read the documentation for functions that you use, to ensure you are using them correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario\n",
    "\n",
    "A client approaches you to solve a machine learning problem for them. They run a pathology lab that processes histological images for healthcare providers and they have created a product that measures the same features as in the *Wisconsin breast cancer data set* though using different acquisitions and processing methods. This makes their method much faster than existing ones, but it is also slightly noisier. The dataset contains measurements of several features that describe characteristics of cell nuclei present in digital images of breast tissue samples. These features include the mean, standard error, and \"worst\" (i.e., largest) values of measurements such as radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, and fractal dimension. Each feature is represented by a numeric value, and each data point represents a sample from either a malignant (cancerous) or benign (non-cancerous) breast tissue.\n",
    "\n",
    "The client want to be able to diagnose *malignant* cancer (and distinguish them from *benign* growths) by employing machine learning techniques, and they have asked you to implement this for them.\n",
    "\n",
    "Their requirements are:\n",
    " 1) have at least a 95% probability of detecting malignant cancer when it is present;\n",
    " 2) have no more than 1 in 10 healthy cases (those with benign tumours) labelled as positive (malignant).\n",
    " \n",
    "They have hand-labelled 300 samples for you, which is all they have at the moment.\n",
    "\n",
    "Please follow the instructions below, which will vary in level of detail, as appropriate to the marks given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code imports some libraries that you will need. \n",
    "# You should not need to modify it, though you are expected to make other imports later in your code.\n",
    "\n",
    "# Common imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "\n",
    "# Plot setup\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "mpl.rc('axes', labelsize=7)\n",
    "mpl.rc('xtick', labelsize=6)\n",
    "mpl.rc('ytick', labelsize=6)\n",
    "mpl.rc('figure', dpi=240)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** [1 point]\n",
    "\n",
    "Load the dataset Do this from the csv file, `assignment2.csv`. Extract the feature names for use later on. The first column is our target and it contains the labels (benign and malignant). Note that we will be treating the _malignant_ case as our _positive_ case, as this is the standard convention in medicine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"assignment2.csv\")\n",
    "\n",
    "feature_names = data.columns[1:]\n",
    "\n",
    "# The following code is used by the autograder\n",
    "# make sure your variable that contains the answer from this step is the one assigned to step1_1data\n",
    "step1_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Step 2** [3 points]\n",
    "\n",
    "As this data is well curated by the client already, you do not need to worry about outliers, missing values or imputation in this case, but be aware that this is the exception, not the rule.\n",
    "\n",
    "To familiarise yourself with the nature and information contained in the data, display histograms for the data according to the following instructions:\n",
    " - Isolate each group of features (mean, standard error, and worst) into its own DataFrame.\n",
    " - you are provided with code to display histograms for each feature in the _mean_ group. On _each_ histogram the two classes displayed together in one plot \n",
    " - **repeat this** for the _standard error_ and _worst_ groups; \n",
    "\n",
    "**Based on the histograms and using the function *corr()* or *numpy corrcoef()* which do you think are the 3 strongest features for discriminating between the classes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1920 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate the mean, standard error, and worst groups into separate dataframes\n",
    "mean_group = data.filter(regex='_mean')\n",
    "error_group = data.filter(regex='_se')\n",
    "worst_group = data.filter(regex='_worst')\n",
    "\n",
    "#  You can comment out the plotting code before uploading it to gradescope for faster evaluation\n",
    "class_labels = ['benign', 'malignant'] \n",
    "fig = plt.figure(figsize=(12, 8))  \n",
    "\n",
    "# Plot the histograms for each feature in the mean group with both classes displayed together\n",
    "for i, feature in enumerate(mean_group.columns):  \n",
    "    plt.subplot(3, 4, i+1)  \n",
    "    plt.hist([mean_group[feature][data['label'] == 'benign'], mean_group[feature]\n",
    "             [data['label'] == 'malignant']], label=class_labels)  \n",
    "    plt.xlabel(\"Feature Value\")  \n",
    "    plt.ylabel(\"Frequency\")  \n",
    "    plt.legend() \n",
    "    plt.title(feature)  \n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()  \n",
    "\n",
    "for i, feature in enumerate(error_group.columns):  \n",
    "    plt.subplot(3, 4, i+1)  \n",
    "    plt.hist([mean_group[feature][data['label'] == 'benign'], mean_group[feature]\n",
    "             [data['label'] == 'malignant']], label=class_labels)  \n",
    "    plt.xlabel(\"Feature Value\")  \n",
    "    plt.ylabel(\"Frequency\")  \n",
    "    plt.legend() \n",
    "    plt.title(feature)  \n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()  \n",
    "\n",
    "for i, feature in enumerate(worst_group.columns):  \n",
    "    plt.subplot(3, 4, i+1)  \n",
    "    plt.hist([mean_group[feature][data['label'] == 'benign'], mean_group[feature]\n",
    "             [data['label'] == 'malignant']], label=class_labels)  \n",
    "    plt.xlabel(\"Feature Value\")  \n",
    "    plt.ylabel(\"Frequency\")  \n",
    "    plt.legend() \n",
    "    plt.title(feature)  \n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()  \n",
    "\n",
    "# Add a column 'is_malignant' as a binary representation of the target variable\n",
    "data['is_malignant'] = (data.iloc[:, 0] == 'malignant').astype(int)\n",
    "\n",
    "# Based on the histograms and correlation, determine the 3 strongest features for discriminating between the classes\n",
    "correlations = data.corr().abs()['is_malignant'].sort_values(ascending=False)\n",
    "ranked_features = correlations.index[1:4].tolist()\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step2_data = ranked_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Step3** [3 points]\n",
    "\n",
    "Convert the labels into 0s and 1s so that benign is represented by 0 and malignant is represented by 1.\n",
    "\n",
    "Split the dataset into appropriate subsets for training, validation and test sets. You must choose the size of each subset. However, make sure that the proportion of the two classes is consistent across all datasets using the _stratify_ option, as used in workshops 5 and 6. Verify the size and label distribution in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 210\n",
      "Validation set size: 45\n",
      "Test set size: 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    " \n",
    "# Convert labels to 0 (benign) and 1 (malignant)\n",
    "data['label'] = data['label'].map({'benign': 0, 'malignant': 1})\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# First, split into train and test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Then, split the remaining train set into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Print the size of each resulting subset\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Validation set size:\", len(X_val))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step3_data = [len(X_train) , len(X_val) , len(X_test)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step4** [4 points]\n",
    "\n",
    "Baseline measurements \n",
    "\n",
    "For our classification task we will consider **three simple baseline cases**:\n",
    "1) predicting all samples to be negative (class 1)\n",
    "2) predicting all samples to be positive (class 2)\n",
    "3) making a random prediction for each sample with equal probability for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create arrays to hold the predicted labels for each baseline case\n",
    "baseline1_preds = np.zeros(len(y_val))  # Predict all samples as negative (class 0)\n",
    "baseline2_preds = np.ones(len(y_val))   # Predict all samples as positive (class 1)\n",
    "baseline3_preds = np.random.randint(0, 2, len(y_val))  # Make random predictions for each sample with equal probability for each class\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step4_data = [baseline1_preds, baseline2_preds, baseline3_preds]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step5** [2 points]\n",
    "\n",
    "Write a function that returns the following metrics for all baseline measures created in Step4, use the function and print the metrics:\n",
    "\n",
    " - recall\n",
    " - precision\n",
    " - auc\n",
    " - f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 1 metrics:\n",
      "  Recall: 0.000\n",
      "  Precision: 0.000\n",
      "  AUC: 0.500\n",
      "  F1 Score: 0.000\n",
      "\n",
      "Baseline 2 metrics:\n",
      "  Recall: 1.000\n",
      "  Precision: 0.489\n",
      "  AUC: 0.500\n",
      "  F1 Score: 0.657\n",
      "\n",
      "Baseline 3 metrics:\n",
      "  Recall: 0.500\n",
      "  Precision: 0.524\n",
      "  AUC: 0.533\n",
      "  F1 Score: 0.512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sptro\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return rec, prec, auc, f1\n",
    "\n",
    "# calculates and prints the metrics for each metric\n",
    "\n",
    "baseline_metrics = []\n",
    "\n",
    "for i, baseline_preds in enumerate(step4_data, start=1):\n",
    "    rec, prec, auc, f1 = calculate_metrics(y_val, baseline_preds)\n",
    "    baseline_metrics.append((rec, prec, auc, f1))\n",
    "    print(f\"Baseline {i} metrics:\")\n",
    "    print(f\"  Recall: {rec:.3f}\")\n",
    "    print(f\"  Precision: {prec:.3f}\")\n",
    "    print(f\"  AUC: {auc:.3f}\")\n",
    "    print(f\"  F1 Score: {f1:.3f}\")\n",
    "    print()\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step5_data = calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step6** [3 points]\n",
    "\n",
    "Create a function which takes in the true labels and the predictions and returns the following parameters:\n",
    "\n",
    "* Number of True Positives (TP)\n",
    "* Number of True Negatives (TN)\n",
    "* Number of False Positive (FP)\n",
    "* Number of False Negative (FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# This function returns the number of TP, TN, FP, FN.\n",
    "def get_values(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tp = cm[1, 1]\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step6_data = get_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step7 [3 points]**\n",
    "\n",
    "Based on the above baseline tests and the client's requirements, **choose a performance metric** to use for evaluating/driving your machine learning methods.\n",
    "\n",
    "Choose the best metric of the five and assign to the variable below.\n",
    "* For AUC, use \"roc_auc\"\n",
    "* For recall, use \"recall\"\n",
    "* For precision, use \"precision\"\n",
    "* For F1 Score, use \"f1\"\n",
    "\n",
    "***NOTE:*** Not all the metrics are equally useful for meeting the requirements of the client, thereby, choose only the one most suitable metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose the best metric of the five and assign to the variable below. The variable takes a string.\n",
    "chosen_metric = \"roc_auc\"\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step7_data = chosen_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step8** [3 points]\n",
    "\n",
    "**Creating a SGD baseline**\n",
    "\n",
    "For a stronger baseline, **train the Stochastic Gradient Descent classifier (SGD) model** on the training data and evaluate it on the validation data (as seen in workshop 4). Use a Pipeline for this which considers the preprocessing and the SGD model. For this baseline case use the default settings for all the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pre-processing pipeline that includes imputation (as even though we don't strictly need it here it is a good habit to always include it) and other appropriate pre-processing. Create another pipeline for the SGD model which has preprocessing pipeline as the pre-processing part. Train the model and evaluate it on the validation data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD validation score: 1.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Create pre-processing pipeline\n",
    "preproc_pl = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create SGD model pipeline which has preproc_pl as the pre-processing part\n",
    "sgd_base = Pipeline([\n",
    "    ('preproc', preproc_pl),\n",
    "    ('classifier', SGDClassifier())\n",
    "])\n",
    "\n",
    "# fit the SGD pipeline on the training data\n",
    "sgd_base.fit(X_train, y_train)\n",
    "\n",
    "# evaluate on the validation data\n",
    "val_score = sgd_base.score(X_val, y_val)\n",
    "print(f\"SGD validation score: {val_score:.5f}\")\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step8_data = sgd_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step9** [2 points]\n",
    "\n",
    "On the validation data, calculate and print or display the **normalized** version of the confusion matrix.  Given the normalized confusion matrix, **what is the _probability_ that a sample from a person with a malignant tumour is given a result that they do not have cancer?  Which of the client's two criteria does this relate to, and is this baseline satisfying this criterion or not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix:\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cmat_raw = confusion_matrix(y_val, sgd_base.predict(X_val))\n",
    "\n",
    "# Normalize confusion matrix\n",
    "cmat = cmat_raw / cmat_raw.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Display or print cmat\n",
    "print(\"Normalized confusion matrix:\\n\", cmat)\n",
    "\n",
    "# Assign the required probability to the variable below\n",
    "# Probability that a sample from a person with a malignant tumor is given a result that they do not have cancer\n",
    "required_prob = cmat[1, 0]\n",
    "\n",
    "# Choose which of the client's two criteria does this relate to (1 or 2)\n",
    "criteria = 2\n",
    "\n",
    "# Does the baseline model satisfy this criterion? (\"YES\" or \"NO\")\n",
    "satisfy = \"YES\" if required_prob <= 0.05 else \"NO\"\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step9_data = cmat, required_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main classifier \n",
    "\n",
    "In this part, you need to try different models for classification, check their performance and determine the best for the present scenario.\n",
    "\n",
    "Follow best practice as much as possible here. You must make all the choices and decisions yourself, and strike a balance between computation time and performance.\n",
    "\n",
    "You can use any of the sklearn functions used in workshops 3, 4, 5 and 6. Other hyper-parameter optimisation functions apart from these cannot be used (even if they are good and can be part of best practice in other situations - for this assignment everyone should assume they only have very limited computation resources and limit themselves to these functions). Hint: Use **GridSearchCV** to solve these steps.\n",
    "\n",
    "**Display the performance of the different classifiers and the optimised hyperparameters.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step10** [3 point]\n",
    "\n",
    "**Train and optimise the hyperparameters** to give the best performance for a **KNN (K-Nearest Neighbour)** classifier. For this model consider and  evaluate the following parameters:\n",
    "\n",
    "* n_neighbors (with no value greater than 20)\n",
    "* weights\n",
    "* algorithm\n",
    "* metric\n",
    "* p (with no value greater than 20)\n",
    "\n",
    "Read the documentation about this model to find some proper ranges and ensure that you use the pipeline created in Step8 to train this model. How to decide what are the best setting of parameters? -> use the best metric identified in the **Step7**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 384 candidates, totalling 768 fits\n",
      "knn_best_parameters : {'classifier__algorithm': 'auto', 'classifier__metric': 'minkowski', 'classifier__n_neighbors': 2, 'classifier__p': 4, 'classifier__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Write your solution here\n",
    "\n",
    "# Put the pipeline with the appropriate model\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_pl = Pipeline(steps=[('preproc', preproc_pl), ('classifier', knn_clf)])\n",
    "\n",
    "# Set the parameters for GridSearchCV\n",
    "knn_params = {\n",
    "    'classifier__n_neighbors': list(range(1, 5)),\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'classifier__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'classifier__p': list(range(1, 5))\n",
    "}\n",
    "\n",
    "\n",
    "# Use GridSearchCV here with cv=5, using the chosen_metric from Step 7\n",
    "knn_model = GridSearchCV(knn_pl, param_grid=knn_params, cv=2, scoring=step7_data, n_jobs=-1, verbose=1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "print(f'knn_best_parameters : {knn_model.best_params_}') \n",
    "\n",
    "# Return best parameters in a dictionary\n",
    "knn_best_parameters = knn_model.best_params_\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step10_data = knn_model, knn_best_parameters, knn_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step11** [2 points]\n",
    "\n",
    "**Train and optimise the hyperparameters** to give the best performance for a **Decision tree classifier** classifier. For this model consider and  evaluate the following parameters:\n",
    "\n",
    "* criterion\n",
    "* max_depth (with no value greater than 20)\n",
    "* min_samples_split (with no value greater than 20)\n",
    "* min_samples_leaf (with no value greater than 20)\n",
    "* max_features\n",
    "\n",
    "Read the documentation about this model to find some proper ranges and ensure that you use the pipeline created in Step8 to train this model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
      "dt_best_parameters : {'classifier__criterion': 'gini', 'classifier__max_depth': 1, 'classifier__max_features': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Put the pipeline with the appropriate model\n",
    "dt_pl = Pipeline([\n",
    "    ('preprocessing', preproc_pl),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "dt_params = {\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': list(range(1, 5)),\n",
    "    'classifier__min_samples_split': list(range(2, 5)),\n",
    "    'classifier__min_samples_leaf': list(range(1, 5)),\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "\n",
    "# Use GridSearchCV with cv=5\n",
    "dt_model = GridSearchCV(dt_pl, param_grid=dt_params, cv=5, scoring=step7_data, n_jobs=-1, verbose=1)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "print(f'dt_best_parameters : {dt_model.best_params_}')\n",
    "\n",
    "# Return best parameters in a dictionary\n",
    "dt_best_parameters = dt_model.best_params_\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step11_data = dt_model, dt_best_parameters, dt_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step12** [2 points]\n",
    "\n",
    "**Train and optimise the hyperparameters** to give the best performance for a **C-Support Vector Classification** classifier. For this model consider and  evaluate the following parameters:\n",
    "\n",
    "* C. Regularization parameter (with no value greater than 100)\n",
    "* kernel\n",
    "* gamma\n",
    "\n",
    "Read the documentation about this model to find some proper ranges and ensure that you use the pipeline created in Step8 to train this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "svc_best_parameters : {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Put the pipeline with the appropriate model\n",
    "svc_pl = Pipeline([\n",
    "    ('preprocessing', preproc_pl),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "svc_params = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV with cv=5\n",
    "svc_model = GridSearchCV(svc_pl, param_grid=svc_params, cv=5, scoring=step7_data, n_jobs=-1, verbose=1)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "print(f'svc_best_parameters : {svc_model.best_params_}')\n",
    "\n",
    "# Return best parameters in a dictionary\n",
    "svc_best_parameters = svc_model.best_params_\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step12_data = svc_model, svc_best_parameters, svc_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step13** [2 points]\n",
    "\n",
    "**Train and optimise the hyperparameters** to give the best performance for a **SGD classifier** classifier. For this model consider and  evaluate the following parameters:\n",
    "\n",
    "* loss \n",
    "* penalty\n",
    "* alpha (with no value greater than 100)\n",
    "* learning_rate\n",
    "* eta0 (with no value greater than 100)\n",
    "\n",
    "Read the documentation about this model to find some proper ranges and ensure that you use the pipeline created in Step8 to train this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2100 candidates, totalling 10500 fits\n",
      "sgd_best_parameters : {'classifier__alpha': 0.0001, 'classifier__eta0': 0.01, 'classifier__learning_rate': 'constant', 'classifier__loss': 'hinge', 'classifier__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Put the pipeline with the appropriate model\n",
    "sgd_pl = Pipeline([\n",
    "    ('preprocessing', preproc_pl),\n",
    "    ('classifier', SGDClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "sgd_params = {\n",
    "    'classifier__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'classifier__eta0': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV with cv=5\n",
    "sgd_model = GridSearchCV(sgd_pl, param_grid=sgd_params, cv=5, scoring=step7_data, n_jobs=-1, verbose=1)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "print(f'sgd_best_parameters : {sgd_model.best_params_}')\n",
    "\n",
    "# Return best parameters in a dictionary\n",
    "sgd_best_parameters = sgd_model.best_params_\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step13_data = sgd_model, sgd_best_parameters, sgd_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step14** [2 points]\n",
    "\n",
    "Considering the previous results using **GridSearchCV** for each one of the main classifiers, retrieve the obtained score using the best parameters in each case. Also indicate which are the three **best** models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Best models: ['knn', 'dt', 'svc']\n"
     ]
    }
   ],
   "source": [
    "# Assign the best score for each model\n",
    "knn_best_cv_scoring = knn_model.best_score_\n",
    "dt_best_cv_scoring = dt_model.best_score_\n",
    "svc_best_cv_scoring = svc_model.best_score_\n",
    "sgd_best_cv_scoring = sgd_model.best_score_\n",
    "\n",
    "print(knn_best_cv_scoring)\n",
    "print(dt_best_cv_scoring)\n",
    "print(svc_best_cv_scoring)\n",
    "print(sgd_best_cv_scoring)\n",
    "\n",
    "# Create a dictionary with classifier names as keys and their best scores as values\n",
    "model_scores = {\n",
    "    'knn': knn_best_cv_scoring,\n",
    "    'dt': dt_best_cv_scoring,\n",
    "    'svc': svc_best_cv_scoring,\n",
    "    'sgd': sgd_best_cv_scoring\n",
    "}\n",
    "\n",
    "# Sort the dictionary by values (scores) in descending order\n",
    "sorted_model_scores = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# What are the three best models so far?\n",
    "best_models = [model[0] for model in sorted_model_scores[:3]]\n",
    "\n",
    "print(f\"Best models: {best_models}\")\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step14_data = best_models, knn_best_cv_scoring, dt_best_cv_scoring, svc_best_cv_scoring, sgd_best_cv_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step15** [0 points]\n",
    "\n",
    "Once you have performed the search of the best parameters for each one of these models, you can display the general performance of each model using the next function **plot_compare_classifier_score**. An example plot using the function provided would look like the following:\n",
    "\n",
    "<center><img src=\"scoring_curves.jpg\" width=900 alt=\"Example loss curve plot\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to check the performance of each parameter.\n",
    "def pooled_var(stds):\n",
    "    # https://en.wikipedia.org/wiki/Pooled_variance#Pooled_standard_deviation\n",
    "    n = 5 # size of each group\n",
    "    return np.sqrt(sum((n-1)*(stds**2))/ len(stds)*(n-1))\n",
    "\n",
    "# Check the performance for each model (knn, dt, svc and sgd). Use plot_gridSearchCV_loss_curve() function.\n",
    "def plot_gridSearchCV_loss_curve(cv_results,grid_params,title):\n",
    "\n",
    "    df = pd.DataFrame(cv_results)\n",
    "    results = ['mean_test_score',\n",
    "               'mean_train_score',\n",
    "               'std_test_score',\n",
    "               'std_train_score']\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(grid_params),\n",
    "                             figsize = (5*len(grid_params), 7),\n",
    "                             sharey='row')\n",
    "    axes[0].set_ylabel(\"Score\", fontsize=25)\n",
    "\n",
    "\n",
    "    for idx, (param_name, param_range) in enumerate(grid_params.items()):\n",
    "        grouped_df = df.groupby(f'param_{param_name}')[results]\\\n",
    "            .agg({'mean_train_score': 'mean',\n",
    "                  'mean_test_score': 'mean',\n",
    "                  'std_train_score': pooled_var,\n",
    "                  'std_test_score': pooled_var})\n",
    "\n",
    "        previous_group = df.groupby(f'param_{param_name}')[results]\n",
    "        axes[idx].set_xlabel(param_name, fontsize=30)\n",
    "        axes[idx].set_ylim(0.0, 1.1)\n",
    "        lw = 2\n",
    "        axes[idx].plot(param_range, grouped_df['mean_train_score'], label=\"Training score\",\n",
    "                    color=\"darkorange\", lw=lw)\n",
    "        axes[idx].fill_between(param_range,grouped_df['mean_train_score'] - grouped_df['std_train_score'],\n",
    "                        grouped_df['mean_train_score'] + grouped_df['std_train_score'], alpha=0.2,\n",
    "                        color=\"darkorange\", lw=lw)\n",
    "        axes[idx].plot(param_range, grouped_df['mean_test_score'], label=\"Cross-validation score\",\n",
    "                    color=\"navy\", lw=lw)\n",
    "        axes[idx].fill_between(param_range, grouped_df['mean_test_score'] - grouped_df['std_test_score'],\n",
    "                        grouped_df['mean_test_score'] + grouped_df['std_test_score'], alpha=0.2,\n",
    "                        color=\"navy\", lw=lw)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.suptitle(f'{title} Validation curves', fontsize=30)\n",
    "    fig.legend(handles, labels, loc=8, ncol=2, fontsize=20)\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25, top=0.85)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step16** [3 points]\n",
    "\n",
    "Having identified the best three models in Step 14, train them using their best parameters on the training data, and then make predictions on the validation set. Finally, calculate and display the following metrics for each case:\n",
    "\n",
    "* recall\n",
    "* precision\n",
    "* auc score\n",
    "* f1 score\n",
    "\n",
    "***HINT:*** Use the function you have created in Step5 to obtain the above metrics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Metrics: (1.0, 1.0, 1.0, 1.0)\n",
      "Decision Tree Metrics: (1.0, 1.0, 1.0, 1.0)\n",
      "SVC Metrics: (1.0, 1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Train the best three models using the best parameters\n",
    "best_knn = knn_model.best_estimator_\n",
    "best_dt = dt_model.best_estimator_\n",
    "best_svc = svc_model.best_estimator_\n",
    "\n",
    "# Fit the models\n",
    "best_knn.fit(X_train, y_train)\n",
    "best_dt.fit(X_train, y_train)\n",
    "best_svc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions_model1 = best_knn.predict(X_val)\n",
    "predictions_model2 = best_dt.predict(X_val)\n",
    "predictions_model3 = best_svc.predict(X_val)\n",
    "\n",
    "# Calculate metrics using Step5 function\n",
    "metrics_model1 = calculate_metrics(y_val, predictions_model1)\n",
    "metrics_model2 = calculate_metrics(y_val, predictions_model2)\n",
    "metrics_model3 = calculate_metrics(y_val, predictions_model3)\n",
    "\n",
    "print(\"KNN Metrics:\", metrics_model1)\n",
    "print(\"Decision Tree Metrics:\", metrics_model2)\n",
    "print(\"SVC Metrics:\", metrics_model3)\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step16_data = [(predictions_model1, predictions_model2, predictions_model3),\n",
    "               (metrics_model1, metrics_model2, metrics_model3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step17** [4 points]\n",
    "\n",
    "**Final performance**\n",
    "\n",
    "Choose the best model of the top 3 you obtained in **Step14**. Calculate and display an unbiased performance measure that you can present to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding the best model for SVC\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "grid_search_svc = GridSearchCV(svc, param_grid, scoring='f1', cv=5)\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "\n",
    "svc_best_model = grid_search_svc.best_estimator_\n",
    "svc_best_params = grid_search_svc.best_params_\n",
    "svc_best_cv_scoring = grid_search_svc.best_score_\n",
    "\n",
    "'''\n",
    "Assign the training features, training labels that you would use for this step to the variables\n",
    "below.\n",
    "'''\n",
    "X_train_final = X_train\n",
    "y_train_final = y_train\n",
    "\n",
    "# Assign the best model to the variable below and train it\n",
    "final_model = svc_best_model\n",
    "final_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Assign the predictions made from your chosen best model for the unbiased estimate to the variable below.\n",
    "predictions_final_model = final_model.predict(X_val)\n",
    "\n",
    "# Choose a performance metric based on the client's requirement and assign the result to the variable below.\n",
    "chosen_performance_metric_result = f1_score(y_val, predictions_final_model)\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step17_data = (predictions_final_model, chosen_performance_metric_result, X_train_final, y_train_final, final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step18** [3 points]\n",
    "\n",
    "**Rank features**\n",
    "\n",
    "Although it is only possible to know the true usefulness of a feature when you've combined it with others in a machine learning method, it is still helpful to have some measure for how discriminative each feature is on its own.  One common method for doing this is to calculate a *T-score* (often used in statistics, and in the **LDA** machine learning method) for each feature. The formula for the *T-score* is \n",
    "\n",
    "$$\n",
    "  T_{score} =  \\frac{(mean(x_{2}) - mean(x_{1}))}{0.5(stddev(x_{2}) + stddev(x_{1}))}\n",
    "$$\n",
    "\n",
    "where $x_{1}$ and $x_{2}$ are the datasets corresponding to the two classes. Large values for the *T-score* (either positive or negative) indicate discriminative ability. Define a function which returns this *T-score*. For this process use the entire dataset.\n",
    "\n",
    "**Using the defined function, calculate the *T-score* for each feature and obtain the best 4 features according to this score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implement this function to calculate T score\n",
    "def calculate_t_score(x1, x2):\n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "    mean_diff = np.mean(x2) - np.mean(x1)\n",
    "    pooled_std_dev = np.sqrt((np.var(x2) * n2 + np.var(x1) * n1) / (n1 + n2 - 2))\n",
    "    epsilon = 1e-10  # Add a small constant to avoid division by zero\n",
    "    t_score = mean_diff / (np.sqrt((pooled_std_dev ** 2 / n2) + (pooled_std_dev ** 2 / n1)) + epsilon)\n",
    "    return t_score\n",
    "\n",
    "\n",
    "# Split the training data into two datasets corresponding to the two classes\n",
    "class_0 = X_train[y_train == 0]\n",
    "class_1 = X_train[y_train == 1]\n",
    "\n",
    "# Calculate the T score for each feature\n",
    "t_scores = []\n",
    "for feature in X_train.columns:\n",
    "    t_score = calculate_t_score(class_0[feature], class_1[feature])\n",
    "    t_scores.append((feature, t_score))\n",
    "\n",
    "# Sort the features by their T score (descending order) and get the top 4\n",
    "sorted_features = sorted(t_scores, key=lambda x: abs(x[1]), reverse=True)\n",
    "best_four_features = [feature[0] for feature in sorted_features[:4]]\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step18_data = best_four_features.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step19 [2 points]**\n",
    "\n",
    "You can visualize the results given by your model using a decision boundary. For this step, use the best two features (based on the previos step) and create a decision boundary plot. For this, use the best model obtained from Step17. The visualization of decision boundaries should be done using `DecisionBoundaryDisplay` from sklearn.inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sptro\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1536x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign the name of the best feature obtained in step18 to the variable below. (string)\n",
    "feature_one = best_four_features[0]\n",
    "\n",
    "# Assign the name of the second best feature obtained in step18 to the variable below. (string)\n",
    "feature_two = best_four_features[1]\n",
    "\n",
    "# Assign the training dataset that you would want to use for this step to the variable below\n",
    "data2d = X_train[[feature_one, feature_two]]\n",
    "\n",
    "# Fit the final model on the 2D dataset\n",
    "final_model.fit(data2d, y_train)\n",
    "\n",
    "def plot_decision_boundary(model, X, y, feature_one, feature_two):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[feature_one].min() - 1, X[feature_one].max() + 1\n",
    "    y_min, y_max = X[feature_two].min() - 1, X[feature_two].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    plt.scatter(X[feature_one], X[feature_two], c=y, edgecolors='k', marker='o', s=50, cmap=plt.cm.coolwarm)\n",
    "    plt.xlim(X[feature_one].min() - 0.5, X[feature_one].max() + 0.5)\n",
    "    plt.ylim(X[feature_two].min() - 0.5, X[feature_two].max() + 0.5)\n",
    "    plt.title(f\"Decision surface for tree trained on {feature_one} and {feature_two}\")\n",
    "\n",
    "# Call the function to create the decision boundary plot\n",
    "# Comment out the following lines before uploading to gradescope\n",
    "plot_decision_boundary(final_model, data2d, y_train, feature_one, feature_two)\n",
    "plt.show()\n",
    "\n",
    "# The following line of code is used by the autograder\n",
    "step19_data = feature_one, feature_two, data2d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Round\n",
    "\n",
    "After presenting your initial results to the client they come back to you and say that they have done some financial analysis and it would save them a lot of time and money if they did not have to analyse every cell, which is needed to get the \"worst\" features. Instead, they can quickly get accurate estimates for the \"mean\" and \"standard error\" features from a much smaller, randomly selected set of cells.\n",
    "\n",
    "They ask you to **give them a performance estimate for the same problem, but without using any of the \"worst\" features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step20** [2 points]\n",
    "\n",
    "Create a new dataset according to the specifications of the client in round 2. After that, split the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22804\\2521583849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Remove the \"worst\" features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"worst\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Remove the \"worst\" features\n",
    "data_r2 = data.drop(columns=data.filter(regex=\"worst\").columns)\n",
    "\n",
    "# Split the data into training and test sets (80-20)\n",
    "train_data_r2, test_data_r2 = train_test_split(data_r2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data into training and validation sets (80-20)\n",
    "train_data_r2, val_data_r2 = train_test_split(train_data_r2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assign the data to each variable appropriately\n",
    "X_train_r2 = train_data_r2.drop(columns=[\"id\", \"diagnosis\"])\n",
    "y_train_r2 = train_data_r2[\"diagnosis\"]\n",
    "\n",
    "X_test_r2 = test_data_r2.drop(columns=[\"id\", \"diagnosis\"])\n",
    "y_test_r2 = test_data_r2[\"diagnosis\"]\n",
    "\n",
    "X_val_r2 = val_data_r2.drop(columns=[\"id\", \"diagnosis\"])\n",
    "y_val_r2 = val_data_r2[\"diagnosis\"]\n",
    "\n",
    "# Print the size of each resulting subset\n",
    "print(\"Training set size (second round):\", len(X_train_r2))\n",
    "print(\"Validation set size (second round):\", len(X_val_r2))\n",
    "print(\"Test set size (second round):\", len(X_test_r2))\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step20_data = [X_train_r2.shape, X_val_r2.shape, X_test_r2.shape]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step21** [3 points]\n",
    "\n",
    "Train the best model obtained in the first round on the new dataset and find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the GridSearchCV instance you have obtained in this step to the variable below.\n",
    "final_model_r2 = ...\n",
    "print(f'best_parameters_r2: {final_model_r2.best_params_}')\n",
    "\n",
    "# Assign the best parameter dictionary to the variable below.\n",
    "best_parameters_r2 = ...\n",
    "\n",
    "# The following code is used by the autograder.\n",
    "step21_data = final_model_r2, best_parameters_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step22** [3 points]\n",
    "\n",
    "Considering the best parameters identified in the previous step, train your best model using those parameters and calculate and display an unbiased performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Assign the training features, training labels that you would use for this step to the variables\n",
    "below.\n",
    "''' \n",
    "X_train_final_r2 = ...\n",
    "y_train_final_r2 = ...\n",
    "\n",
    "# Assign the best model you have trained again in order to get an unbiased performance estimate.\n",
    "final_model_r2 = ...\n",
    "\n",
    "# Assign the predictions made from your chosen best model for the unbiased estimate to the variable below.\n",
    "predictions_final_model_r2 = ...\n",
    "\n",
    "# Choose a performance metric based on the client's requirement and assign the result to the variable below.\n",
    "performance_metric_result_r2 = ...\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step22_data = (predictions_final_model_r2, performance_metric_result_r2,X_train_final_r2, y_train_final_r2,final_model_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step23** [2 points]\n",
    "\n",
    "For this step you need to compare the final performance obtained in round 1 with the performance given in round 2. Don't run your models again, use the results from step17 and step22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final performance for 2nd round\n",
    "final_performance_r1 = ...\n",
    "\n",
    "# Final performance for 2nd round\n",
    "final_performance_r2 = ...\n",
    "\n",
    "# What is your best model, \"r1\" or \"r2\". Put your answer in the variable final_answer (example: final_answer = \"r2\")\n",
    "final_answer = ...\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step23_data = (final_performance_r1, final_performance_r2,final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step24** [3 points]\n",
    "\n",
    "Once you have gone through the rigorous process of testing and evaluating different models with various parameters and in diverse circumstances, you now have a robust model capable of generalizing well to unseen data.\n",
    "\n",
    "The client has provided data about a new patient in a table format, and is expecting you to make a prediction about the person's condition as soon as possible. The following table contains the information provided by the client.\n",
    "\n",
    "| Characteristic | Value |\n",
    "| --- | --- |\n",
    "| mean radius |13.970546 | \n",
    "| mean texture|15.660529 | \n",
    "| mean perimeter | 91.432976| \n",
    "| mean area |600.575775 | \n",
    "| mean smoothness |0.099883 | \n",
    "| mean compactness | NaN| \n",
    "| mean concavity | 0.07505| \n",
    "| mean concave points | 0.023223| \n",
    "| mean symmetry | 0.186472| \n",
    "| mean fractal dimension | 0.05446|\n",
    "| radius error | 0.321022 | \n",
    "| texture error |1.044633 | \n",
    "| perimeter error |2.324773 | \n",
    "| area error |31.333479 | \n",
    "| smoothness error | 0.005675| \n",
    "| compactness error |0.023401 | \n",
    "| concavity error |0.026742 | \n",
    "| concave points error |0.009808 | \n",
    "| symmetry error | 0.029254| \n",
    "| fractal dimension error |0.00325 |\n",
    "| worst radius |12.728135 | \n",
    "| worst texture | 23.476671| \n",
    "| worst perimeter |103.834522 | \n",
    "| worst area | 798.832368| \n",
    "| worst smoothness |0.130751 | \n",
    "| worst compactness |0.264469 | \n",
    "| worst concavity |0.247665 | \n",
    "| worst concave points | 0.100153| \n",
    "| worst symmetry |0.301228 | \n",
    "| worst fractal dimension |0.083051 |  \n",
    "\n",
    "Your goal is to inform the client whether the sample corresponds to a benign or malignant case. Provide the class and also the probability that the sample belongs to the malignant class.\n",
    "\n",
    "Note: If your best model corresponds to SGD using loss='perceptron', you can use decision_function instead of predict_proba to obtain the confidence score for your sample instead of the probability of belonging to the malignant class. Refer to the documentation of SGDClassifier for more information on this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your new data in form of a dataframe\n",
    "new_sample = ...\n",
    "# Print the data\n",
    "print(new_sample)\n",
    "\n",
    "# Use the best model to predict. \n",
    "\n",
    "# Prediction of the class. You need to say if the sample is bening or malignant (\"malignant\" or \"benign\")\n",
    "prediction_sample = ...\n",
    "\n",
    "# Probability or confidence score of the sample belonging to the malignant class\n",
    "probability_sample = ...\n",
    "\n",
    "# Print your results\n",
    "print(\"The class for this sample is \", prediction_sample)\n",
    "\n",
    "# NOTE: in the case of SGD, Confidence score values will not be bounded within 0 and 1.\n",
    "print(\"The probability / confidence score of belonging to malignant class is \", probability_sample)\n",
    "\n",
    "# The following code is used by the autograder\n",
    "step24_data = (new_sample,prediction_sample, probability_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "step01": {
     "name": "step01",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step02": {
     "name": "step02",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step03": {
     "name": "step03",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step04": {
     "name": "step04",
     "points": 4,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step05": {
     "name": "step05",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step06": {
     "name": "step06",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step07": {
     "name": "step07",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step08": {
     "name": "step08",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step09": {
     "name": "step09",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step10": {
     "name": "step10",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step11": {
     "name": "step11",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step12": {
     "name": "step12",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step13": {
     "name": "step13",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step14": {
     "name": "step14",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step15": {
     "name": "step15",
     "points": 0,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step16": {
     "name": "step16",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step17": {
     "name": "step17",
     "points": 4,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step18": {
     "name": "step18",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step19": {
     "name": "step19",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step20": {
     "name": "step20",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step21": {
     "name": "step21",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step22": {
     "name": "step22",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step23": {
     "name": "step23",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "step24": {
     "name": "step24",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
