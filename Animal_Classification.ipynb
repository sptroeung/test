{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BONXLLRegH70"
      },
      "source": [
        "# **Animal Competition (15%)**\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "For the non-competition mode, we will use the Animal (https://cloudstor.aarnet.edu.au/plus/s/cZYtNAeVhWD6uBX) dataset. This dataset contains images of 151 different animals. \n",
        "\n",
        "The dataset contains a total of 6270 images corresponding to the name of animal types.\n",
        "\n",
        "All images are RGB images of 224 pixels wide by 224 pixels high in .jpg format. The images are separated in 151 folders according to their respective class.\n",
        "\n",
        "The task is to categorize each animal into one of 151 categories. \n",
        "\n",
        "We provide baseline code that includes the following features:\n",
        "\n",
        "*   Loading and Analysing the dataset using torchvision.\n",
        "*   Defining a simple convolutional neural network. \n",
        "*   How to use existing loss function for the model learning. \n",
        "*   Train the network on the training data. \n",
        "*   Test the trained network on the testing data. \n",
        "\n",
        "The following changes could be considered:\n",
        "\n",
        "-------\n",
        "1. \"Transfer\" Learning (ie use a model pre-trained another dataset)\n",
        "2. Change of advanced training parameters: Learning Rate, Optimizer, Batch-size, Number of Max Epochs, and Drop-out. \n",
        "3. Use of a new loss function.\n",
        "4. Data augmentation\n",
        "5. Architectural Changes: Batch Normalization, Residual layers, etc.\n",
        "6. Others\n",
        "\n",
        "Your code should be modified from the provided baseline. A pdf report of a maximum of two pages is required to explain the changes you made from the baseline, why you chose those changes, and the improvements they achieved.\n",
        "\n",
        "Marking Rules:\n",
        "-------\n",
        "We will mark the competition based on the final test accuracy on testing images and your report.\n",
        "\n",
        "Final mark (out of 50) = acc_mark + efficiency mark + report mark\n",
        "###Acc_mark 10:\n",
        "\n",
        "We will rank all the submission results based on their test accuracy. Zero improvement over the baseline yields 0 marks. Maximum improvement over the baseline will yield 10 marks. There will be a sliding scale applied in between.\n",
        "\n",
        "###Efficiency mark 10:\n",
        "\n",
        "Efficiency considers not only the accuracy, but the computational cost of running the model (flops: https://en.wikipedia.org/wiki/FLOPS). Efficiency for our purposes is defined to be the ratio of accuracy (in %) to Gflops. Please report the computational cost for your final model and include the efficiency calculation in your report. Maximum improvement over the baseline will yield 10 marks. Zero improvement over the baseline yields zero marks, with a sliding scale in between.\n",
        "\n",
        "###Report mark 30:\n",
        "Your report should comprise:\n",
        "1. An introduction showing your understanding of the task and of the baseline model: [10 marks]\n",
        "\n",
        "2. A description of how you have modified aspects of the system to improve performance. [10 marks]\n",
        "\n",
        "A recommended way to present a summary of this is via an \"ablation study\" table, eg:\n",
        "\n",
        "|Method1|Method2|Method3|Accuracy|\n",
        "|---|---|---|---|\n",
        "|N|N|N|60%|\n",
        "|Y|N|N|65%|\n",
        "|Y|Y|N|77%|\n",
        "|Y|Y|Y|82%|\n",
        "\n",
        "3. Explanation of the methods for reducing the computational cost and/or improve the trade-off between accuracy and cost: [5 marks]\n",
        "\n",
        "4. Limitations/Conclusions: [5 marks] \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6osXOBOQIeFi"
      },
      "outputs": [],
      "source": [
        "##################################################################################################################################\n",
        "### Subject: Computer Vision \n",
        "### Year: 2023\n",
        "### Student Name: ABC, XYZ\n",
        "### Student ID: a123456, a654321\n",
        "### Comptetion Name: Animal Classification Competition\n",
        "### Final Results:\n",
        "### ACC:         FLOPs:\n",
        "##################################################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsXCfZg3KA5B"
      },
      "outputs": [],
      "source": [
        "# Importing libraries. \n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# To avoid non-essential warnings \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from torchvision import datasets, transforms, models \n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pn8oVaFKEfa"
      },
      "outputs": [],
      "source": [
        "# Mounting G-Drive to get your dataset. \n",
        "# To access Google Colab GPU; Go To: Edit >>> Netebook Settings >>> Hardware Accelarator: Select GPU. \n",
        "# Reference: https://towardsdatascience.com/google-colab-import-and-export-datasets-eccf801e2971 \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset path. You should change the dataset path to the location that you place the data.\n",
        "data_dir = '/content/drive/MyDrive/Datasets/animal/'\n",
        "classes = os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6PfFlDfK41q"
      },
      "outputs": [],
      "source": [
        "# Performing Image Transformations. \n",
        "##Hints: Data Augmentation can be applied here. Have a look on RandomFlip, RandomRotation...\n",
        "train_transform = transforms.Compose([\n",
        "            transforms.Resize(112),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.CenterCrop(112),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.488), (0.2172)),\n",
        "        ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lgLwj4VsH5y"
      },
      "outputs": [],
      "source": [
        "# Checking the dataset training size.\n",
        "dataset = ImageFolder(data_dir, transform=train_transform)\n",
        "print('Size of training dataset :', len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KMeP9V4OoDa"
      },
      "outputs": [],
      "source": [
        "# Viewing one of images shape.\n",
        "img, label = dataset[100]\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhgDWEtmOtgl"
      },
      "outputs": [],
      "source": [
        "# Preview one of the images..\n",
        "def show_image(img, label):\n",
        "    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
        "    plt.imshow(img.permute(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La4sXlGpOyob"
      },
      "outputs": [],
      "source": [
        "show_image(*dataset[200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3aLCchAO1uQ"
      },
      "outputs": [],
      "source": [
        "# Setting seed so that value won't change everytime. \n",
        "# Splitting the dataset to training, validation, and testing category.\n",
        "torch.manual_seed(10)\n",
        "val_size = len(dataset)//20\n",
        "test_size = len(dataset)//10\n",
        "train_size = len(dataset) - val_size - test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oeDLvlsO1lx"
      },
      "outputs": [],
      "source": [
        "# Random Splitting. \n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_ds), len(val_ds),len(test_ds)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RntURgaIRaTp"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZkgiO-XRdxQ"
      },
      "outputs": [],
      "source": [
        "# Multiple images preview. \n",
        "for images, labels in train_loader:\n",
        "    fig, ax = plt.subplots(figsize=(18,10))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpH6HJSuRhAe"
      },
      "outputs": [],
      "source": [
        " # Baseline model class for training and validation purpose. Evaluation metric function - Accuracy.\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"\n",
        "    Computes the accuracy over the k top predictions for the specified values of k\n",
        "    In top-3 accuracy you give yourself credit for having the right answer\n",
        "    if the right answer appears in your top five guesses.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = 3\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        # st()\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        # st()\n",
        "        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        # correct = (pred == target.view(1, -1).expand_as(pred))\n",
        "        correct = (pred == target.unsqueeze(dim=0)).expand_as(pred)\n",
        "\n",
        "\n",
        "\n",
        "        correct_3 = correct[:3].reshape(-1).float().sum(0, keepdim=True)\n",
        "\n",
        "        return correct_3.mul_(1.0 / batch_size)\n",
        "#def accuracy(outputs, labels):\n",
        " #   _, preds = torch.max(outputs, dim=1)\n",
        "  #  return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss, Hints: the loss function can be changed to improve the accuracy\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels, (5))           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-2gGT4iRthd"
      },
      "outputs": [],
      "source": [
        " # To check wether Google Colab GPU has been assigned/not. \n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnJ0fHw3Ry6D"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device\n",
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg1yB_o7R1rz"
      },
      "outputs": [],
      "source": [
        "input_size = 3*112*112\n",
        "output_size = 151"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8hKhWrZSiER"
      },
      "outputs": [],
      "source": [
        "# Convolutional Network - Baseline\n",
        "class ConvolutionalNetwork(ImageClassificationBase):\n",
        "    def __init__(self, classes):\n",
        "        super().__init__()\n",
        "        self.num_classes=classes\n",
        "        self.conv1=nn.Conv2d(3,64,5,1)\n",
        "        self.conv2=nn.Conv2d(64,128,3,1)\n",
        "        self.conv3=nn.Conv2d(128,128,3,1)\n",
        "        self.conv4=nn.Conv2d(128,128,3,1)\n",
        "        self.fc1=nn.Linear(128*5*5,self.num_classes)\n",
        "    def forward(self,X):\n",
        "        X=F.relu(self.conv1(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=F.relu(self.conv2(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=F.relu(self.conv3(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=F.relu(self.conv4(X))\n",
        "        X=F.max_pool2d(X,2,2)\n",
        "        X=X.view(-1,128*5*5)\n",
        "        X=self.fc1(X)\n",
        "        \n",
        "        return F.log_softmax(X, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds1_BIy6Sse5"
      },
      "outputs": [],
      "source": [
        "# Model print\n",
        "num_classes = 151\n",
        "model = ConvolutionalNetwork(num_classes)\n",
        "#model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwePT8W8Sxob"
      },
      "outputs": [],
      "source": [
        "# We can check the input and the output shape\n",
        "for images, labels in train_loader:\n",
        "    out = model(images)\n",
        "    print('images.shape:', images.shape)    \n",
        "    print('out.shape:', out.shape)\n",
        "    print('out[0]:', out[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Slbs7i2bTNYX"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_loader, device)\n",
        "val_dl = DeviceDataLoader(val_loader, device)\n",
        "to_device(model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp66PsS8T_tk"
      },
      "outputs": [],
      "source": [
        "# Functions for evaluation and training.\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1A9PYs1Ugt_"
      },
      "outputs": [],
      "source": [
        "model = to_device(model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y473tduFUi7I"
      },
      "outputs": [],
      "source": [
        "history=[evaluate(model, val_loader)]\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS27vmjWUk0M"
      },
      "outputs": [],
      "source": [
        "# Hints: The following parameters can be changed to improve the accuracy\n",
        "print(test_size)\n",
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYoHc3F6U2aQ"
      },
      "outputs": [],
      "source": [
        "history+= fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qglm75IWU4cb"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs')\n",
        "    plt.show()\n",
        "    \n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L_30nphU70R"
      },
      "outputs": [],
      "source": [
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR4Z6VhoU9ph"
      },
      "outputs": [],
      "source": [
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF0Svy9WU_FQ"
      },
      "outputs": [],
      "source": [
        "evaluate(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30W_gAqhVI09"
      },
      "source": [
        "##FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIx3zX87VNBw"
      },
      "outputs": [],
      "source": [
        "  #The code from https://cloudstor.aarnet.edu.au/plus/s/PcSc67ZncTSQP0E can be used to count flops\n",
        "  #Download the code.\n",
        "  !wget -c https://cloudstor.aarnet.edu.au/plus/s/hXo1dK9SZqiEVn9/download\n",
        "  !mv download FLOPs_counter.py\n",
        "  #!rm -rf download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhLcWbq2VRYa"
      },
      "outputs": [],
      "source": [
        "from FLOPs_counter import print_model_parm_flops\n",
        "input = torch.randn(1, 3, 112, 112) # The input size should be the same as the size that you put into your model \n",
        "#Get the network and its FLOPs\n",
        "num_classes = 151\n",
        "model = ConvolutionalNetwork(num_classes)\n",
        "print_model_parm_flops(model, input, detail=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "30W_gAqhVI09"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}